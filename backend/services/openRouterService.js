const axios = require('axios');
const dotenv = require('dotenv');

dotenv.config();

// Utiliser le service IA local si configur√©, sinon OpenRouter
const AI_SERVICE_URL = process.env.AI_SERVICE_URL;
const OPENROUTER_API_URL = process.env.OPENROUTER_API_URL || 'https://openrouter.ai/api/v1';
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;
const OPENROUTER_MODEL = process.env.OPENROUTER_MODEL || 'openai/gpt-4o-mini';
const AI_MODEL = process.env.AI_MODEL || OPENROUTER_MODEL;

// D√©terminer quelle API utiliser
const USE_LOCAL_AI = !!AI_SERVICE_URL;
const API_URL = USE_LOCAL_AI ? AI_SERVICE_URL : OPENROUTER_API_URL;

/**
 * Appel g√©n√©rique √† l'API IA (locale ou OpenRouter)
 * @param {String} prompt - Le prompt √† envoyer
 * @param {Object} options - Options suppl√©mentaires (temperature, max_tokens, etc.)
 * @returns {Promise<String>} - R√©ponse de l'IA
 */
const callAIService = async (prompt, options = {}) => {
  try {
    // Si on utilise le service local, pas besoin de cl√© API
    if (!USE_LOCAL_AI && !OPENROUTER_API_KEY) {
      throw new Error('OPENROUTER_API_KEY non configur√© dans les variables d\'environnement');
    }

    // Construire l'URL de l'API
    // Pour les services locaux (Ollama), l'endpoint est g√©n√©ralement /api/chat
    // Pour OpenRouter, c'est /chat/completions
    let apiEndpoint;
    if (USE_LOCAL_AI) {
      // Pour Ollama, l'endpoint est /api/chat
      // Si l'URL contient d√©j√† /api, utiliser directement
      if (API_URL.includes('/api')) {
        apiEndpoint = `${API_URL}/chat`;
      } else if (API_URL.includes('/v1')) {
        apiEndpoint = `${API_URL}/chat/completions`;
      } else {
        // Format Ollama standard: http://host:port/api/chat
        apiEndpoint = `${API_URL}/api/chat`;
      }
    } else {
      apiEndpoint = `${API_URL}/chat/completions`;  // Format OpenRouter
    }

    // Pr√©parer les headers
    const headers = {
      'Content-Type': 'application/json',
    };

    // Ajouter l'autorisation seulement si on utilise OpenRouter
    if (!USE_LOCAL_AI && OPENROUTER_API_KEY) {
      headers['Authorization'] = `Bearer ${OPENROUTER_API_KEY}`;
      headers['HTTP-Referer'] = process.env.OPENROUTER_HTTP_REFERER || 'http://localhost:5000';
      headers['X-Title'] = process.env.OPENROUTER_APP_NAME || 'LockHeaven';
    }

    // Pour les services locaux (Ollama), on peut aussi ajouter une cl√© si n√©cessaire
    if (USE_LOCAL_AI && process.env.AI_API_KEY) {
      headers['Authorization'] = `Bearer ${process.env.AI_API_KEY}`;
    }

    console.log(`üîÑ [AI] Appel ${USE_LOCAL_AI ? 'service IA local' : 'OpenRouter'} - URL: ${apiEndpoint}`);

    // Pr√©parer le payload selon le format de l'API
    let payload;
    if (USE_LOCAL_AI && apiEndpoint.includes('/api/chat')) {
      // Format Ollama: /api/chat
      payload = {
        model: AI_MODEL,
        messages: [
          {
            role: 'system',
            content: 'Tu es un assistant IA expert en analyse de documents professionnels. Tu r√©ponds toujours en fran√ßais et de mani√®re pr√©cise et structur√©e.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        stream: false,
        options: {
          temperature: options.temperature || 0.3,
          num_predict: options.max_tokens || 2000,
          top_p: options.top_p || 1,
        },
      };
    } else {
      // Format OpenAI/OpenRouter: /v1/chat/completions ou /chat/completions
      payload = {
        model: USE_LOCAL_AI ? AI_MODEL : OPENROUTER_MODEL,
        messages: [
          {
            role: 'system',
            content: 'Tu es un assistant IA expert en analyse de documents professionnels. Tu r√©ponds toujours en fran√ßais et de mani√®re pr√©cise et structur√©e.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: options.temperature || 0.3,
        max_tokens: options.max_tokens || 2000,
        top_p: options.top_p || 1,
        frequency_penalty: options.frequency_penalty || 0,
        presence_penalty: options.presence_penalty || 0,
      };
    }

    const response = await axios.post(
      apiEndpoint,
      payload,
      {
        headers,
        timeout: options.timeout || 60000,
      }
    );

    // Extraire le contenu selon le format de r√©ponse
    let content;
    if (USE_LOCAL_AI && apiEndpoint.includes('/api/chat')) {
      // Format Ollama
      content = response.data.message?.content || response.data.response;
    } else {
      // Format OpenAI/OpenRouter
      content = response.data.choices[0]?.message?.content;
    }
    if (!content) {
      console.error('R√©ponse compl√®te:', JSON.stringify(response.data, null, 2));
      throw new Error(`R√©ponse vide de l'API ${USE_LOCAL_AI ? 'IA locale' : 'OpenRouter'}`);
    }

    console.log(`‚úÖ [AI] R√©ponse re√ßue (${content.length} caract√®res)`);
    return content;
  } catch (error) {
    console.error(`‚ùå [AI] Erreur lors de l'appel ${USE_LOCAL_AI ? 'service IA local' : 'OpenRouter'}:`, error.message);
    if (error.response) {
      console.error('   Status:', error.response.status);
      console.error('   Data:', JSON.stringify(error.response.data, null, 2));
    }
    throw new Error(`Erreur ${USE_LOCAL_AI ? 'service IA local' : 'OpenRouter API'}: ${error.message}`);
  }
};

// Alias pour compatibilit√©
const callOpenRouter = callAIService;

/**
 * Parser une r√©ponse JSON de l'IA
 * @param {String} response - R√©ponse textuelle de l'IA
 * @returns {Object} - Objet pars√©
 */
const parseJSONResponse = (response) => {
  try {
    // Essayer de parser directement
    return JSON.parse(response);
  } catch (error) {
    // Essayer d'extraire le JSON si la r√©ponse contient du texte autour
    const jsonMatch = response.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      try {
        return JSON.parse(jsonMatch[0]);
      } catch (e) {
        console.warn('Impossible de parser le JSON, retour de la r√©ponse brute');
        return { raw: response };
      }
    }
    throw new Error('R√©ponse non-JSON de l\'IA');
  }
};

/**
 * G√©n√©rer un r√©sum√© et des points cl√©s pour un document
 * @param {String} text - Texte du document
 * @param {String} filename - Nom du fichier
 * @returns {Promise<Object>} - R√©sum√© et points cl√©s
 */
exports.generateSummary = async (text, filename = '') => {
  const prompt = `Tu es un expert en analyse de documents. Analyse le document suivant et g√©n√®re un r√©sum√© professionnel.

**Document:** ${filename || 'Document sans nom'}

**Contenu:**
${text.substring(0, 50000)} ${text.length > 50000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Instructions:**
1. G√©n√®re un r√©sum√© concis et professionnel (3-5 phrases) qui capture l'essence du document
2. Identifie 5-7 points cl√©s les plus importants
3. Le r√©sum√© doit √™tre en fran√ßais et adapt√© √† un contexte professionnel
4. Les points cl√©s doivent √™tre des phrases courtes et actionnables

**Format de r√©ponse (JSON strict):**
{
  "summary": "R√©sum√© du document en 3-5 phrases",
  "keyPoints": [
    "Point cl√© 1",
    "Point cl√© 2",
    "Point cl√© 3",
    "Point cl√© 4",
    "Point cl√© 5"
  ],
  "category": "Cat√©gorie du document (ex: Rapport, Contrat, Pr√©sentation, etc.)",
  "language": "Langue d√©tect√©e du document"
}

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire.`;

  try {
    const response = await callOpenRouter(prompt, {
      temperature: 0.3,
      max_tokens: 1500,
    });

    const parsed = parseJSONResponse(response);
    
    return {
      summary: parsed.summary || 'R√©sum√© non disponible',
      keyPoints: parsed.keyPoints || [],
      category: parsed.category || 'Document',
      language: parsed.language || 'fr',
      generatedAt: new Date(),
    };
  } catch (error) {
    console.error('Erreur g√©n√©ration r√©sum√©:', error);
    throw error;
  }
};

/**
 * Extraire des entit√©s nomm√©es d'un document
 * @param {String} text - Texte du document
 * @returns {Promise<Object>} - Entit√©s extraites
 */
exports.extractEntities = async (text) => {
  const prompt = `Analyse le texte suivant et extrais toutes les entit√©s nomm√©es importantes.

**Texte:**
${text.substring(0, 30000)} ${text.length > 30000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Instructions:**
Extrais et cat√©gorise les entit√©s suivantes:
- **personnes**: Noms de personnes mentionn√©es
- **organisations**: Entreprises, institutions, organisations
- **dates**: Dates importantes (format ISO: YYYY-MM-DD)
- **lieux**: Villes, pays, adresses
- **montants**: Montants financiers avec devise
- **mots_cles**: 10-15 mots-cl√©s les plus importants
- **themes**: 3-5 th√®mes principaux du document

**Format de r√©ponse (JSON strict):**
{
  "personnes": ["Nom 1", "Nom 2"],
  "organisations": ["Organisation 1", "Organisation 2"],
  "dates": ["2024-01-15", "2024-12-31"],
  "lieux": ["Paris", "France"],
  "montants": ["1000 EUR", "5000 USD"],
  "mots_cles": ["mot-cl√© 1", "mot-cl√© 2"],
  "themes": ["Th√®me 1", "Th√®me 2"]
}

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire.`;

  try {
    const response = await callAIService(prompt, {
      temperature: 0.2,
      max_tokens: 2000,
    });

    const parsed = parseJSONResponse(response);
    
    return {
      personnes: parsed.personnes || [],
      organizations: parsed.organisations || [],
      dates: parsed.dates || [],
      locations: parsed.lieux || [],
      amounts: parsed.montants || [],
      keywords: parsed.mots_cles || [],
      themes: parsed.themes || [],
      extractedAt: new Date(),
    };
  } catch (error) {
    console.error('Erreur extraction entit√©s:', error);
    return {
      personnes: [],
      organizations: [],
      dates: [],
      locations: [],
      amounts: [],
      keywords: [],
      themes: [],
      extractedAt: new Date(),
    };
  }
};

/**
 * Analyser le sentiment et le ton d'un document
 * @param {String} text - Texte du document
 * @returns {Promise<Object>} - Analyse de sentiment
 */
exports.analyzeSentiment = async (text) => {
  const prompt = `Analyse le sentiment et le ton du texte suivant.

**Texte:**
${text.substring(0, 20000)} ${text.length > 20000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Instructions:**
D√©termine:
1. Le sentiment g√©n√©ral (positif, neutre, n√©gatif)
2. Le ton du document (formel, informel, technique, commercial, etc.)
3. Le niveau de confiance/urgence (√©chelle de 1 √† 10)
4. Les √©motions principales d√©tect√©es

**Format de r√©ponse (JSON strict):**
{
  "sentiment": "positif|neutre|n√©gatif",
  "sentiment_score": 0.75,
  "ton": "formel|informel|technique|commercial",
  "confidence_level": 7,
  "emotions": ["confiance", "optimisme"],
  "summary": "Br√®ve description du sentiment g√©n√©ral"
}

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire.`;

  try {
    const response = await callAIService(prompt, {
      temperature: 0.3,
      max_tokens: 500,
    });

    return parseJSONResponse(response);
  } catch (error) {
    console.error('Erreur analyse sentiment:', error);
    return {
      sentiment: 'neutre',
      sentiment_score: 0.5,
      ton: 'neutre',
      confidence_level: 5,
      emotions: [],
      summary: 'Analyse non disponible',
    };
  }
};

/**
 * G√©n√©rer des analytics et insights sur un document
 * @param {String} text - Texte du document
 * @param {Object} metadata - M√©tadonn√©es du document
 * @returns {Promise<Object>} - Analytics et insights
 */
exports.generateAnalytics = async (text, metadata = {}) => {
  const prompt = `Analyse ce document en profondeur et g√©n√®re des analytics et insights professionnels.

**M√©tadonn√©es:**
- Nom: ${metadata.filename || 'Non sp√©cifi√©'}
- Type: ${metadata.mimeType || 'Non sp√©cifi√©'}
- Taille: ${metadata.size ? `${(metadata.size / 1024).toFixed(2)} KB` : 'Non sp√©cifi√©'}
- Tags: ${metadata.tags ? metadata.tags.join(', ') : 'Aucun'}

**Contenu:**
${text.substring(0, 40000)} ${text.length > 40000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Instructions:**
G√©n√®re une analyse compl√®te incluant:
1. **Complexit√©**: Niveau de complexit√© du document (simple, moyen, complexe)
2. **Longueur_analyse**: Nombre de mots, paragraphes estim√©s
3. **Type_document**: Type pr√©cis (Rapport financier, Contrat, Pr√©sentation, etc.)
4. **Secteur**: Secteur d'activit√© identifi√©
5. **Recommandations**: 3-5 recommandations d'action bas√©es sur le contenu
6. **Risques**: Risques potentiels identifi√©s (si applicable)
7. **Opportunites**: Opportunit√©s identifi√©es (si applicable)
8. **Prochaines_etapes**: Prochaines √©tapes sugg√©r√©es

**Format de r√©ponse (JSON strict):**
{
  "complexity": "simple|moyen|complexe",
  "word_count_estimate": 1500,
  "paragraph_count_estimate": 25,
  "document_type": "Type pr√©cis du document",
  "sector": "Secteur d'activit√©",
  "recommendations": [
    "Recommandation 1",
    "Recommandation 2"
  ],
  "risks": [
    "Risque 1",
    "Risque 2"
  ],
  "opportunities": [
    "Opportunit√© 1",
    "Opportunit√© 2"
  ],
  "next_steps": [
    "√âtape 1",
    "√âtape 2"
  ],
  "insights": "Insight principal en 2-3 phrases"
}

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire.`;

  try {
    const response = await callOpenRouter(prompt, {
      temperature: 0.4,
      max_tokens: 2000,
    });

    return parseJSONResponse(response);
  } catch (error) {
    console.error('Erreur g√©n√©ration analytics:', error);
    return {
      complexity: 'moyen',
      word_count_estimate: 0,
      paragraph_count_estimate: 0,
      document_type: 'Document',
      sector: 'Non sp√©cifi√©',
      recommendations: [],
      risks: [],
      opportunities: [],
      next_steps: [],
      insights: 'Analytics non disponibles',
    };
  }
};

/**
 * Comparer deux documents
 * @param {String} text1 - Texte du premier document
 * @param {String} text2 - Texte du second document
 * @param {String} filename1 - Nom du premier fichier
 * @param {String} filename2 - Nom du second fichier
 * @returns {Promise<Object>} - Comparaison
 */
exports.compareDocuments = async (text1, text2, filename1 = '', filename2 = '') => {
  const prompt = `Compare deux documents et identifie les similitudes, diff√©rences et insights.

**Document 1:** ${filename1 || 'Document 1'}
${text1.substring(0, 20000)} ${text1.length > 20000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Document 2:** ${filename2 || 'Document 2'}
${text2.substring(0, 20000)} ${text2.length > 20000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Instructions:**
Compare les deux documents et identifie:
1. Similitudes principales
2. Diff√©rences cl√©s
3. Points de convergence
4. Points de divergence
5. Recommandations bas√©es sur la comparaison

**Format de r√©ponse (JSON strict):**
{
  "similarities": [
    "Similarit√© 1",
    "Similarit√© 2"
  ],
  "differences": [
    "Diff√©rence 1",
    "Diff√©rence 2"
  ],
  "convergence_points": [
    "Point de convergence 1"
  ],
  "divergence_points": [
    "Point de divergence 1"
  ],
  "recommendations": [
    "Recommandation 1"
  ],
  "summary": "R√©sum√© de la comparaison en 3-4 phrases"
}

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire.`;

  try {
    const response = await callAIService(prompt, {
      temperature: 0.4,
      max_tokens: 2000,
    });

    return parseJSONResponse(response);
  } catch (error) {
    console.error('Erreur comparaison documents:', error);
    throw error;
  }
};

/**
 * G√©n√©rer des tags automatiques pour un document
 * @param {String} text - Texte du document
 * @param {String} filename - Nom du fichier
 * @returns {Promise<Array>} - Liste de tags
 */
exports.generateTags = async (text, filename = '') => {
  const prompt = `G√©n√®re 5-10 tags pertinents pour ce document.

**Document:** ${filename || 'Document sans nom'}

**Contenu:**
${text.substring(0, 30000)} ${text.length > 30000 ? '\n\n[... contenu tronqu√© ...]' : ''}

**Instructions:**
G√©n√®re des tags en fran√ßais qui d√©crivent:
- Le sujet principal
- Le type de document
- Le secteur/th√®me
- Les concepts cl√©s

**Format de r√©ponse (JSON strict):**
{
  "tags": ["tag1", "tag2", "tag3", "tag4", "tag5"]
}

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire.`;

  try {
    const response = await callAIService(prompt, {
      temperature: 0.3,
      max_tokens: 300,
    });

    const parsed = parseJSONResponse(response);
    return parsed.tags || [];
  } catch (error) {
    console.error('Erreur g√©n√©ration tags:', error);
    return [];
  }
};

/**
 * V√©rifier la disponibilit√© de l'API IA (locale ou OpenRouter)
 * @returns {Promise<Boolean>} - √âtat de l'API
 */
exports.checkOpenRouterConnection = async () => {
  try {
    if (USE_LOCAL_AI) {
      if (!AI_SERVICE_URL) {
        console.warn('‚ö†Ô∏è  [AI] AI_SERVICE_URL non configur√©');
        return false;
      }
      console.log(`üîÑ [AI] V√©rification de la connexion au service IA local: ${AI_SERVICE_URL}`);
    } else {
      if (!OPENROUTER_API_KEY) {
        console.warn('‚ö†Ô∏è  [AI] OPENROUTER_API_KEY non configur√©');
        return false;
      }
      console.log('üîÑ [AI] V√©rification de la connexion √† OpenRouter API');
    }

    // Test simple avec un prompt minimal
    await callAIService('R√©ponds simplement "OK"', {
      max_tokens: 10,
      timeout: 10000,
    });

    console.log(`‚úÖ [AI] Connexion √† ${USE_LOCAL_AI ? 'service IA local' : 'OpenRouter API'} r√©ussie`);
    return true;
  } catch (error) {
    console.error(`‚ùå [AI] Connexion √©chou√©e (${USE_LOCAL_AI ? 'service IA local' : 'OpenRouter'}):`, error.message);
    return false;
  }
};

module.exports = {
  callOpenRouter,
  callAIService,
  generateSummary: exports.generateSummary,
  extractEntities: exports.extractEntities,
  analyzeSentiment: exports.analyzeSentiment,
  generateAnalytics: exports.generateAnalytics,
  compareDocuments: exports.compareDocuments,
  generateTags: exports.generateTags,
  checkOpenRouterConnection: exports.checkOpenRouterConnection,
};
